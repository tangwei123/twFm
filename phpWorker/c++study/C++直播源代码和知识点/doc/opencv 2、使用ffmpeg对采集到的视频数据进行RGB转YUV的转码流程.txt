一般情况下与opencv一起配合使用

	一、创建转码上下文
		1、SwsContext *vsl = NULL;

	二、初始化转码上下文 //只需要一次不要放入循环
		vsl = sws_getCachedContext(vsl, 原视频宽度，原视频高度，原视频格式(AV_PIX_FMT_BGR24), 目标的宽度， 目标的高度， 目标的格式(AV_PIX_FMT_YUV420P), 编码的格式(SWS_BICUBIC), 0, 0, 0)

	三、初始化frame
		

		AVFrame *yuv = av_frame_alloc();//创建目标帧
		
		yuv->format = AV_PIX_FMT_YUV420P;

		yuv->width = camera.get(CV_CAP_PROP_FRAME_WIDTH);

		yuv->height = camera.get(CV_CAP_PROP_FRAME_HEIGHT);

		yuv->pts = 0;//这儿先设置为0，一会拿到它进行h264编码的时候 需要重新计算，否则都一致，那么avcodec_receive_packet是不能通过的。

		int res = av_frame_get_buffer(yuv, 32);//分配目标帧的数据空间，不需要放在循环中

		if(res < 0){

			失败的情况
		}


	四、开始转码

		uint8_t *indata[8] = {0};

		indata[0] = img.data//img为打开摄像头获取到的数据

		int insize[8] = {0};

		insize[0] = img.cols*img.elemSize();

		sws_scale(vsl, indata(一个数组，数组的0下标存放原视频的数据), insize(一个数组，数组的0下标存放原视频的一行的数据长度), 0, camera.get(CV_CAP_PROP_FRAME_HEIGHT)(原图像的高度), yuv->data(一个数组，目标数据一般直接用创建和分配好内存空间的帧指向data即可，如 yub->data), yuv->linesize(一个数组，目标数据一般直接用创建和分配好内存空间的帧指向linesize即可，如 yub->linesize));//转换完毕返回帧的高度




	总结，实践得到，像素转换这块的代码，是不消耗内存的，只要把 vsl、yuv 在使用之后释放掉就行